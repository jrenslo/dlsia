{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../docs/images/pymsdtorch.png\" width=600 />\n",
    "\n",
    "# Image labeling with Randomized Sparse Mixed Scale Networks\n",
    "\n",
    "Authors: Eric Roberts and Petrus Zwart\n",
    "\n",
    "E-mail: PHZwart@lbl.gov, EJRoberts@lbl.gov\n",
    "___\n",
    "\n",
    "This notebook highlights some basic functionality with the pyMSDtorch package.\n",
    "\n",
    "In this notebook we will demonstrate an ensemble method for image classification. We define a few randomized sparse mixed scale networks that after some fully connected layers yield a image classifier. We will train a few independent networks that will be combined into a single classifier that yields both a probability and associated standard deviation. \n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from dlsia.core import helpers\n",
    "from dlsia.core import train_scripts\n",
    "from dlsia.core.networks import sparsenet\n",
    "from dlsia.core.networks import baggins\n",
    "from dlsia.test_data.twoD import random_shapes\n",
    "from dlsia.core.utils import latent_space_viewer\n",
    "from dlsia.viz_tools import plots\n",
    "from dlsia.viz_tools import plot_autoencoder_image_classification as paic\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import einops\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 100\n",
    "N_labeled = 100\n",
    "\n",
    "N_test  = 5000\n",
    "noise_level = 0.005\n",
    "Nxy = 32\n",
    "\n",
    "train_data = random_shapes.build_random_shape_set_numpy(n_imgs=N_train,\n",
    "                                                        noise_level=noise_level,\n",
    "                                                        n_xy=Nxy)\n",
    "test_data = random_shapes.build_random_shape_set_numpy(n_imgs=N_test,\n",
    "                                                       noise_level=noise_level,\n",
    "                                                       n_xy=Nxy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_shapes_data_numpy(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_one = \"Noisy\" \n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "loader_params = {'batch_size': batch_size, \n",
    "                 'shuffle': True} \n",
    "train_imgs = torch.Tensor(train_data[which_one]).unsqueeze(1)\n",
    "train_labels = torch.Tensor(train_data[\"Label\"]).unsqueeze(1)-1\n",
    "train_labels[N_labeled:]=-1 # remove some labels to highlight 'mixed' training\n",
    "\n",
    "Ttrain_data = TensorDataset(train_imgs,train_labels)\n",
    "train_loader = DataLoader(Ttrain_data, **loader_params)\n",
    "\n",
    "loader_params = {'batch_size': batch_size, \n",
    "                 'shuffle': False} \n",
    "test_images = torch.Tensor(test_data[which_one]).unsqueeze(1)\n",
    "test_labels = torch.Tensor(test_data[\"Label\"]).unsqueeze(1)-1\n",
    "Ttest_data = TensorDataset( test_images, test_labels ) \n",
    "test_loader = DataLoader(Ttest_data, **loader_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build some neural networks\n",
    "\n",
    "There are a number of parameters to play with that impact the size of the network:\n",
    "\n",
    "    - latent_shape: the spatial footprint of the image in latent space. \n",
    "      I don't recommend going below 4x4, because it interferes with the \n",
    "      dilation choices. This is a bit of a annoyiong feature, we need to fix that. \n",
    "      Its on the list.\n",
    "    - out_channels: the number of channels of the latent image. Determines the\n",
    "      dimension of latent space: (channels,latent_shape[-2], latent_shape[-1])\n",
    "    - depth: the depth of the random sparse convolutional encoder.\n",
    "    - hidden channels: The number of channels put out per convolution. \n",
    "    - max_degree / min_degree : This determines how many connections you have per node.\n",
    "    \n",
    "    \n",
    "Other parameters do not impact the size of the network dramatically / at all:\n",
    "\n",
    "    - in_shape: determined by the input shape of the image.\n",
    "    - dilations: the maximum dilation should not exceed the smallest image dimension.\n",
    "    - alpha_range: determines the type of graphs (wide vs skinny). When alpha is large,\n",
    "                   the chances for skinny graphs to be generated increases. \n",
    "                   We don't know which parameter choice is best, so we randomize it's choice.\n",
    "    - gamma_range: no effect unless the maximum degree and min_degree are far apart.\n",
    "                   We don't know which parameter choice is best, so we randomize it's choice.\n",
    "    - pIL,pLO,IO: keep as is. \n",
    "    - stride_base: make sure your latent image size can be generated from the in_shape \n",
    "                   by repeated division of with this number.\n",
    "\n",
    "For the classification, specify the number of output classes. Here we work with 4 shapes, so set it to 4.\n",
    "The dropout rate governs the dropout layers in the classifier part of the networks and doesn't affect the encoder part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate an ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "networks = []\n",
    "Nmodels = 17\n",
    "for ii in range(Nmodels):\n",
    "    rando = sparsenet.SparseLabeler(in_shape=(32, 32), \n",
    "                                          latent_shape=(8, 8), \n",
    "                                          out_classes=4,\n",
    "                                          depth=10, \n",
    "                                          dilations=[1,2,3,4], \n",
    "                                          hidden_channels=3,\n",
    "                                          in_channels=1,\n",
    "                                          out_channels=1, \n",
    "                                          alpha_range=(0.75, 1.0), \n",
    "                                          gamma_range=(0.0, 0.5), \n",
    "                                          max_degree=4, min_degree=2, \n",
    "                                          pIL=0.15, \n",
    "                                          pLO=0.15, \n",
    "                                          IO=False, \n",
    "                                          stride_base=2, \n",
    "                                          dropout_rate=0.15)\n",
    "    networks.append(rando)\n",
    "    pytorch_total_params = helpers.count_parameters(rando)\n",
    "    print( \"Number of parameters:\", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ii in range(Nmodels):\n",
    "    rando = networks[ii]\n",
    "    torch.cuda.empty_cache()\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs=25\n",
    "\n",
    "    criterion_label = nn.CrossEntropyLoss() \n",
    "    optimizer_label = optim.Adam(rando.parameters(), lr=learning_rate)\n",
    "\n",
    "    rv = train_scripts.train_labeling(net=rando.to('cuda:0'),\n",
    "                                                        trainloader=train_loader,\n",
    "                                                        validationloader=test_loader, \n",
    "                                                        NUM_EPOCHS=num_epochs,\n",
    "                                                        criterion=criterion_label,\n",
    "                                                        optimizer=optimizer_label,\n",
    "                                                        device=\"cuda:0\", \n",
    "                                                        show=5, \n",
    "                                                        clip_value=100.0)\n",
    "    plots.plot_training_results_segmentation(rv[1]).show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the individual models has a performance that is far from ideal. When we make an ensemble model things will look a lot better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_model = baggins.model_baggin(networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go over the full validation dataset and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = []\n",
    "std = []\n",
    "true_lbl = []\n",
    "inp_img = []\n",
    "inferred_label = []\n",
    "for batch in test_loader:\n",
    "    true_lbl.append(batch[1])\n",
    "    with torch.no_grad():\n",
    "        inp_img.append(batch[0].cpu())\n",
    "        mp,sp = bagged_model(batch[0], \"cuda:0\", True)\n",
    "        mean.append(mp.cpu())\n",
    "        std.append(sp.cpu())\n",
    "        guessed = torch.argmax(mp, axis=-1)\n",
    "        inferred_label.append(guessed)\n",
    "mean = torch.cat(mean, dim=0)\n",
    "std = torch.cat(std, dim=0)\n",
    "true_lbl = torch.cat(true_lbl, dim=0)    \n",
    "inp_img = torch.cat(inp_img, dim=0)\n",
    "inferred_label = torch.cat(inferred_label, dim=0).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute F1 metrics and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "tmp = train_scripts.segmentation_metrics(mean, \n",
    "                                         true_lbl.flatten().type(torch.LongTensor), \n",
    "                                         missing_label=-1) \n",
    "print(f\"Macro F1 on Test Data {tmp[0]: 6.5f}\")\n",
    "print(f\"Micro F1 on Test Data {tmp[1]: 6.5f}\")\n",
    "print()\n",
    "assert tmp[1] > 0.75 # just to make sure all is ok\n",
    "\n",
    "print(\"--------       The first 5 images encountered     ----------\")\n",
    "for mp,sp,tlbl,ilbl,img in zip(mean, std, true_lbl.flatten(), inferred_label.flatten(), inp_img):    \n",
    "    fig = paic.plot_image_and_class_probabilities(input_img=img[0].numpy(), \n",
    "                                       class_names= [\"Rectangle\",\"Disc\",\"Triangle\",\"Annulus\"],\n",
    "                                       p_classification=mp.numpy(), \n",
    "                                       std_p_classification=sp.numpy())\n",
    "    plt.show()\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break\n",
    "print()        \n",
    "print(\"--------       Incorrectly classified images (5 maximum)   ----------\")\n",
    "count=0\n",
    "for mp,sp,tlbl,ilbl,img in zip(mean, std, true_lbl.flatten(), inferred_label.flatten(), inp_img):\n",
    "    if int(tlbl) != int(ilbl):    \n",
    "        fig = paic.plot_image_and_class_probabilities(input_img=img[0].numpy(), \n",
    "                                           class_names= [\"Rectangle\",\"Disc\",\"Triangle\",\"Annulus\"],\n",
    "                                           p_classification=mp.numpy(), \n",
    "                                           std_p_classification=sp.numpy())\n",
    "        count += 1\n",
    "        if count > 5:\n",
    "            break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to save these networks of course. The issue is that the networks are generated using a random numnber generator, and have no predetermined topology. Because of this feature, some utility functions have been developed.\n",
    "\n",
    "Saving a random network is done via its \"save_network_parameters\" function. If a file name is supplied, a small file will be saved, if the filename is not supplied, an OrderedDict will be returned. A saved network parameter file can be used to instantiate that same network via the SparseLabeler_from_file method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_networks = []\n",
    "for ii in range(Nmodels):\n",
    "    name = \"model_%i.pt\"%ii\n",
    "    networks[ii].save_network_parameters(name)\n",
    "    new_networks.append(SparseNet.SparseLabeler_from_file(name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
