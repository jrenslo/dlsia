{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../docs/images/pymsdtorch.png\" width=600 />\n",
    "\n",
    "# Supervised Image Denosing\n",
    "\n",
    "Authors: Eric Roberts and Petrus Zwart\n",
    "\n",
    "E-mail: PHZwart@lbl.gov, EJRoberts@lbl.gov\n",
    "___\n",
    "\n",
    "This notebook highlights some basic functionality with the pyMSDtorch package.\n",
    "\n",
    "In this notebook we setup a Mixed Scaled Dense Network and train it to denoising image corrupted by Gaussian noise. Subsequently, we will train a number Randomized Sparse Networks on the same task and show how to obtain error estimates via ensemble methods.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import h5py\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlsia.core import helpers\n",
    "from dlsia.core.train_scripts import train_regression\n",
    "from dlsia.core.networks import msdnet, smsnet, baggins\n",
    "from dlsia.test_data.twoD import build_test_data, torch_hdf5_loader\n",
    "from dlsia.viz_tools import plots, draw_sparse_network\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data\n",
    "\n",
    "We produce noisysingle-class data consisting of peaks in guassian noise. \n",
    "\n",
    "Parameters to toggle:\n",
    "\n",
    "- batch_size -- choice of 64 is optimized for 24 GB graphics card\n",
    "- N_imgs -- number of images in training set\n",
    "- N_peaks -- number of circular peaks in each image\n",
    "- N_xy -- size of images\n",
    "- SNR -- signal-to-noise ratio; more noise for lower number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some Parameters to Define ###\n",
    "#################################\n",
    "makeData = True     \n",
    "batch_size = 100\n",
    "num_workers = 0\n",
    "showNoisyData = True\n",
    "use_scaled_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Generate Data ###\n",
    "#####################\n",
    "\n",
    "if makeData == True:\n",
    "    N_imgs = 200 \n",
    "    N_peaks = 8\n",
    "    N_xy = 32\n",
    "    SNR=3\n",
    "    mask_radius = 1.0\n",
    "    \n",
    "    build_test_data.build_data_standard_sets_2d(n_imgs=N_imgs,\n",
    "                                                n_peaks=N_peaks,\n",
    "                                                n_xy=N_xy, \n",
    "                                                snr=SNR,\n",
    "                                                mask_radius=mask_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generator class above can generate the following:\n",
    "- trax_GT -- ground truth\n",
    "- trax_obs -- obstructed, noisy images\n",
    "- trax_obs_norm -- noisy images linearly scaled to interal [0,1]\n",
    "- trax_mask -- binary masked images indicating peak (1) or background (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data ###\n",
    "#################\n",
    "\n",
    "if use_scaled_data == True:\n",
    "    x_label = \"trax_obs_norm\"\n",
    "else:\n",
    "    x_label = \"trax_obs\"\n",
    "    \n",
    "f_train = \"train_data_2d.hdf5\"\n",
    "f_test  = \"test_data_2d.hdf5\"\n",
    "f_validation = \"validate_data_2d.hdf5\"\n",
    "\n",
    "MyData_train = torch_hdf5_loader.Hdf5Dataset2D(filename=f_train, \n",
    "                                                  x_label=x_label, \n",
    "                                                  y_label=\"trax_GT\")\n",
    "MyData_validation = torch_hdf5_loader.Hdf5Dataset2D(filename=f_validation, \n",
    "                                                       x_label=x_label, \n",
    "                                                       y_label=\"trax_GT\")\n",
    "MyData_test = torch_hdf5_loader.Hdf5Dataset2D(filename=f_test, \n",
    "                                                 x_label=x_label, \n",
    "                                                 y_label=\"trax_GT\")\n",
    "\n",
    "loader_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': num_workers}\n",
    "train_loader = DataLoader(MyData_train, **loader_params)\n",
    "loader_params = {'batch_size': batch_size, 'shuffle': False, 'num_workers': num_workers}\n",
    "validation_loader = DataLoader(MyData_validation, **loader_params)\n",
    "test_loader = DataLoader(MyData_test, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Show Noisy Data ###\n",
    "#######################\n",
    "        \n",
    "if showNoisyData == True:\n",
    "    for batch in train_loader:\n",
    "        noisy, mask = batch\n",
    "                \n",
    "        plt.figure(figsize=(12,10))\n",
    "        plt.subplot(321)\n",
    "        plt.imshow(noisy[0,0,:,:]); plt.colorbar(shrink=0.8); plt.title('Noisy'); \n",
    "        plt.subplot(322);\n",
    "        plt.imshow(mask[0,0,:,:]); plt.colorbar(shrink=0.8); plt.title('Mask'); \n",
    "        plt.subplot(323)\n",
    "        plt.imshow(noisy[1,0,:,:]); plt.colorbar(shrink=0.8)\n",
    "        plt.subplot(324);\n",
    "        plt.imshow(mask[1,0,:,:]); plt.colorbar(shrink=0.8) \n",
    "        plt.subplot(325)\n",
    "        plt.imshow(noisy[2,0,:,:]); plt.colorbar(shrink=0.8)\n",
    "        plt.subplot(326);\n",
    "        plt.imshow(mask[2,0,:,:]); plt.colorbar(shrink=0.8) \n",
    "\n",
    "        break\n",
    "        \n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mixed-scale dense convolutional neural network\n",
    "\n",
    "Lots of options to customize. See pyMSDtorch/core/networks/MSDNet.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Networks ###\n",
    "#####################\n",
    "\n",
    "#N_xyz=20\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "num_layers = 40             # Benchmarks used 100, 150, and 200\n",
    "layer_width = 1    # Usually 1\n",
    "max_dilation = 5           # Set to 10 in Pelt, Sethian paper\n",
    "activation = nn.ReLU()\n",
    "normalization = nn.BatchNorm2d\n",
    "final_layer = None\n",
    "\n",
    "msdnet = MSDNet.MixedScaleDenseNetwork(in_channels = in_channels,\n",
    "                                      out_channels = out_channels, \n",
    "                                      num_layers=num_layers, \n",
    "                                      layer_width=layer_width,\n",
    "                                      max_dilation = max_dilation, \n",
    "                                      activation=activation,\n",
    "                                      normalization=normalization,\n",
    "                                      final_layer=final_layer,\n",
    "                                      convolution=nn.Conv2d\n",
    "                                   )\n",
    "pytorch_total_params = sum(p.numel() for p in msdnet.parameters() if p.requires_grad)\n",
    "print(\"Total number of refineable parameters: \", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We perform the following:\n",
    "\n",
    "- specify number of epochs,\n",
    "- select the L2 MSE loss as our scroing criteria,\n",
    "- select a learning rate of 1/1000\n",
    "- choose the popular Adam optimizer for traversing the loss terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100   # set number of epochs\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "optimizer = optim.Adam(msdnet.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = helpers.get_device()\n",
    "msdnet.to(device)\n",
    "msdnet, results = train_regression(msdnet,\n",
    "                                   train_loader,   \n",
    "                                   validation_loader, \n",
    "                                   epochs, \n",
    "                                   criterion, \n",
    "                                   optimizer, \n",
    "                                   device=device, \n",
    "                                   show=10) \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_training_results_regression(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving network and testing our model\n",
    "\n",
    "- Below, we save model parameters using torch.save\n",
    "    - You have option of saving full model, but save parameters and loading them into a newly instantiated network is more flexible\n",
    "\n",
    "- Finally, we load testing data, pass it through the network, and save results as .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics( preds, target):\n",
    "    \"\"\" \n",
    "    Here, the Pearson correlation coefficient is calulated between the network \n",
    "    predictions and the ground truth.\n",
    "    \"\"\"\n",
    "    tmp = corcoef.cc(preds.cpu().flatten(), target.cpu().flatten() )\n",
    "    return(tmp)\n",
    "\n",
    "\n",
    "def segment_imgs(testloader, net, plot=True, std=False):\n",
    "    \"\"\"\n",
    "    This function makes network predictions on testing data found in the 'testloader'\n",
    "    pytorch dataloader object.\n",
    "    \n",
    "    :param testloader: the pyTorch dataloader object used to retrieve testing data\n",
    "    :param net: the trained deep network\n",
    "    :param plot: do you want to plot the first 10 network results using matplotlib?\n",
    "    \n",
    "    :returns seg_imgs: the predicted images, concatenated into a single tensor\n",
    "    :returns noisy_imgs: the input images, concatenated into a single tensor\n",
    "    :returns target_imgs: the ground truth images, concatenated into a single tensor\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    seg_imgs = []\n",
    "    noisy_imgs = []\n",
    "    #target_imgs = []\n",
    "    \n",
    "    #running_CC_test_val = 0.0 \n",
    "    \n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            noisy, target = batch\n",
    "\n",
    "            noisy = torch.FloatTensor(noisy)\n",
    "            noisy = noisy.to(device)#.unsqueeze(1)\n",
    "\n",
    "            sigmas = None\n",
    "            if not std:                \n",
    "                output = net.to(device)(noisy)\n",
    "            else:\n",
    "                output, sigmas = net.to(device)(noisy, 'cpu', True)\n",
    "\n",
    "            if counter == 0:\n",
    "                seg_imgs = output.detach().cpu()\n",
    "                noisy_imgs = noisy.detach().cpu()\n",
    "                target_imgs = target.detach().cpu()\n",
    "                if std:\n",
    "                    sigmas = sigmas.detach().cpu()\n",
    "            else:\n",
    "                seg_imgs = torch.cat((seg_imgs, output.detach().cpu()), 0)\n",
    "                noisy_imgs = torch.cat((noisy_imgs, noisy.detach().cpu()), 0)\n",
    "                target_imgs = torch.cat((target_imgs, target.detach().cpu()), 0)\n",
    "                if std:\n",
    "                    sigmas = sigmas.detach().cpu()\n",
    "\n",
    "\n",
    "            counter+=1\n",
    "            \n",
    "            if plot==True:\n",
    "                for j in range(10):\n",
    "                    if not std:\n",
    "                        print(f'Images for batch # {counter}, number {j}')\n",
    "                        plt.figure(figsize=(22,5))\n",
    "                        plt.subplot(131)\n",
    "                        plt.imshow(noisy.cpu()[j,0,:,:].data); plt.colorbar(shrink=0.8); plt.title('Noisy');             \n",
    "                        plt.subplot(132)            \n",
    "                        plt.imshow(output[j,0,:,:].detach().cpu()); plt.colorbar(shrink=0.8); plt.title('Prediction');            \n",
    "                        plt.subplot(133)            \n",
    "                        plt.imshow(target.cpu()[j,0,:,:].data); plt.colorbar(shrink=0.8); plt.title('Ground Truth'); \n",
    "\n",
    "\n",
    "                        plt.suptitle(\"MSDNet Predictions\", size=24)\n",
    "                        plt.rcParams.update({'font.size': 16})\n",
    "                        plt.tight_layout()\n",
    "\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        print(f'Images for batch # {counter}, number {j}')\n",
    "                        plt.figure(figsize=(22,5))\n",
    "                        plt.subplot(151)\n",
    "                        plt.imshow(noisy.cpu()[j,0,:,:].data); \n",
    "                        plt.colorbar(shrink=0.8); plt.title('Noisy');             \n",
    "                        plt.subplot(152)            \n",
    "                        plt.imshow(output[j,0,:,:].detach().cpu()); \n",
    "                        plt.colorbar(shrink=0.8); plt.title('Prediction');            \n",
    "                        plt.subplot(153)            \n",
    "                        plt.imshow(sigmas[j,0,:,:].detach().cpu()); \n",
    "                        plt.colorbar(shrink=0.8); plt.title('Sigmas');                            \n",
    "                        plt.subplot(154)            \n",
    "                        plt.imshow(output[j,0,:,:].detach().cpu() / sigmas[j,0,:,:].detach().cpu(),vmax=30); \n",
    "                        plt.colorbar(shrink=0.8); plt.title('Signal to Noise');                            \n",
    "                        \n",
    "                        plt.subplot(155)            \n",
    "                        plt.imshow(target.cpu()[j,0,:,:].data); plt.colorbar(shrink=0.8); plt.title('Ground Truth'); \n",
    "\n",
    "\n",
    "                        plt.suptitle(\"MSDNet Predictions\", size=24)\n",
    "                        plt.rcParams.update({'font.size': 16})\n",
    "                        plt.tight_layout()\n",
    "\n",
    "                        plt.show()\n",
    "\n",
    "                        \n",
    "                \n",
    "    \n",
    "    #CC = running_CC_test_val / len(testloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    return seg_imgs, noisy_imgs, target_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output, noisy, target  = segment_imgs(test_loader, msdnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "in_channels = 1 # RGB input image\n",
    "out_channels = 1 # binary output\n",
    "num_layers = 40\n",
    "alpha = 0.20 \n",
    "gamma = 0.0\n",
    "max_k = 6\n",
    "min_k = 3\n",
    "hidden_out_channels = [1] \n",
    "dilation_choices = [1,2,3,4,5] \n",
    "layer_probabilities={'LL_alpha':alpha,\n",
    "                     'LL_gamma': gamma,\n",
    "                     'LL_max_degree':max_k,\n",
    "                     'LL_min_degree':min_k,\n",
    "                     'IL': 0.25,\n",
    "                     'LO': 0.25,\n",
    "                     'IO': False}\n",
    "sizing_settings = {'stride_base':2, #better keep this at 2\n",
    "                   'min_power': 0,\n",
    "                   'max_power': 0}\n",
    "network_type = \"Regression\"\n",
    "nets = [] \n",
    "N_networks = 7\n",
    "\n",
    "for ii in range(N_networks):\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Network %i\"%(ii+1))\n",
    "    net = SMSNet.random_SMS_network(in_channels=in_channels,\n",
    "                                    out_channels=out_channels,\n",
    "                                    in_shape=(32,32),\n",
    "                                    out_shape=(32,32),\n",
    "                                    sizing_settings=sizing_settings,\n",
    "                                    layers=num_layers,\n",
    "                                    dilation_choices=dilation_choices,\n",
    "                                    hidden_out_channels=hidden_out_channels,\n",
    "                                    layer_probabilities=layer_probabilities,\n",
    "                                    network_type=network_type)\n",
    "    \n",
    "    # lets plot the network\n",
    "    net_plot,dil_plot,chan_plot = draw_sparse_network.draw_network(net)\n",
    "    plt.show()\n",
    "\n",
    "    nets.append(net)\n",
    "    \n",
    "    print(\"Start training\")\n",
    "    pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print(\"Total number of refineable parameters: \", pytorch_total_params)\n",
    "    epochs = 100                       # Set number of epochs\n",
    "    criterion = nn.L1Loss()   # For segmenting \n",
    "    LEARNING_RATE = 1e-2\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)    \n",
    "    device = helpers.get_device()\n",
    "    net = net.to(device)\n",
    "    tmp = train_regression(net,\n",
    "                           train_loader,\n",
    "                           test_loader,\n",
    "                           epochs,\n",
    "                           criterion,\n",
    "                           optimizer,\n",
    "                           device,\n",
    "                           show=10)    \n",
    "    net = net.cpu()\n",
    "    plots.plot_training_results_regression(tmp[1]).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_model = baggins.model_baggin(nets,\"regression\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output, noisy, target  = segment_imgs(test_loader, bagged_model, std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}