{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tested-education",
   "metadata": {},
   "source": [
    "<img src=\"../../docs/images/dlsia.png\" width=600 />\n",
    "\n",
    "# Demo on how to save and load models\n",
    "\n",
    "Authors: Eric Roberts and Petrus Zwart\n",
    "\n",
    "E-mail: PHZwart@lbl.gov, EJRoberts@lbl.gov\n",
    "\n",
    "This notebook highlights some basic functionality with the dlsia package.\n",
    "\n",
    "Using the dlsia framework, we initialize convolutional neural networks, and show how to save and load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adult-configuration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejroberts/anaconda3/envs/dlsia/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from dlsia.core import helpers, custom_losses, train_scripts\n",
    "from dlsia.core.networks import msdnet, tunet, tunet3plus, smsnet\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-clear",
   "metadata": {},
   "source": [
    "## Create & load data \n",
    "\n",
    "### Generate random data\n",
    "\n",
    "Let's build some random data: 40 instances of single channel, 36-by-36 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standing-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imgs = 40\n",
    "n_channels = 1\n",
    "n_xy = 36\n",
    "\n",
    "random_data1 = torch.rand((n_imgs, n_channels, n_xy, n_xy))\n",
    "k = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=11, stride=1, padding=5)\n",
    "random_data2 = torch.rand((n_imgs, n_channels, n_xy, n_xy))\n",
    "random_data_gt = k(random_data1) \n",
    "random_data_obs = k(random_data1)  + random_data2*0.50\n",
    "K = 3\n",
    "random_data_obs = random_data_obs[:,:,K:32+K,K:32+K].detach()\n",
    "random_data_gt = random_data_gt[:,:,K:32+K,K:32+K].detach()\n",
    "\n",
    "train_x = random_data_obs[:20,...] \n",
    "train_y = random_data_gt[:20,...]\n",
    "test_x = random_data_obs[20:,...]\n",
    "test_y = random_data_gt[20:,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02de733",
   "metadata": {},
   "source": [
    "### Prep data \n",
    "\n",
    "We cast data as tensors for dlsia pipeline ingestion by making liberal use of the PyTorch Dataloader. This allows us to easy handle and iterative load data into the networks and models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd74a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset( train_x, train_y)\n",
    "test_set = TensorDataset( train_x, train_y)\n",
    "\n",
    "# Specify batch sizes\n",
    "batch_size_train = 20 \n",
    "batch_size_test  = 20\n",
    "\n",
    "# Set Dataloader parameters (Note: we randomly shuffle the training set upon each pass)\n",
    "train_loader_params = {'batch_size': batch_size_train,'shuffle': True}\n",
    "test_loader_params  = {'batch_size': batch_size_test, 'shuffle': False}\n",
    "\n",
    "# Build Dataloaders\n",
    "train_loader = DataLoader(train_set, **train_loader_params)\n",
    "test_loader  = DataLoader(test_set, **test_loader_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-estate",
   "metadata": {},
   "source": [
    "## Construct Networks\n",
    "\n",
    "dlsia offers a variety of different convolutional neural network architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d667cef7",
   "metadata": {},
   "source": [
    "### MSDNet\n",
    "\n",
    "Mixed-scale Dense networks that probe different length scales using dilated convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amended-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "msdnet_model = msdnet.MixedScaleDenseNetwork(in_channels = 1,\n",
    "                                             out_channels = 1, \n",
    "                                             num_layers=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5366c0",
   "metadata": {},
   "source": [
    "### TUNet\n",
    "\n",
    "Tuneable U-Nets with a variety of user-customizable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50113e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunet_model = tunet.TUNet(image_shape=(32,32),\n",
    "                          in_channels=1,\n",
    "                          out_channels=1,\n",
    "                          depth=3, \n",
    "                          base_channels=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc599d92",
   "metadata": {},
   "source": [
    "### TUNet3+\n",
    "\n",
    "A newer UNet modification connecting all encoder and decoder layers via carefully crafted upsampling/downsampling/convolution/concatenation bundles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbab770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunet3plus_model = tunet3plus.TUNet3Plus(image_shape=(32,32),\n",
    "                                         in_channels=1,\n",
    "                                         out_channels=1,\n",
    "                                         depth=3,\n",
    "                                         base_channels=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b26bf2",
   "metadata": {},
   "source": [
    "### SMSNets\n",
    "\n",
    "Sparse Mixed-Scale Networks that lean, randomly & sparsely connected variants of MSDNets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67af01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "smsnet_model = smsnet.random_SMS_network(in_channels=1, \n",
    "                                         out_channels=1, \n",
    "                                         hidden_out_channels=[1],\n",
    "                                         layers=40, \n",
    "                                         dilation_choices=[1,2,3,4],\n",
    "                                         #layer_probabilities=layer_probabilities,\n",
    "                                         network_type=\"Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f19dbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSDNet :      9182 parameters\n",
      "TUNet :       46131 parameters\n",
      "TUNet3plus :  49421 parameters\n",
      "SMSNet :      471 parameters\n"
     ]
    }
   ],
   "source": [
    "# View number of learnable parameters in each network\n",
    "print(\"MSDNet :     \", helpers.count_parameters(msdnet_model), \"parameters\")\n",
    "print(\"TUNet :      \", helpers.count_parameters(tunet_model), \"parameters\")\n",
    "print(\"TUNet3plus : \", helpers.count_parameters(tunet3plus_model), \"parameters\")\n",
    "print(\"SMSNet :     \", helpers.count_parameters(smsnet_model), \"parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092be1dc",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Training parameters\n",
    "\n",
    "Training hyperparameters are chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metallic-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device we will compute on:  cpu\n"
     ]
    }
   ],
   "source": [
    "epochs = 30             \n",
    "criterion = nn.L1Loss()  \n",
    "learning_rate = 1e-2\n",
    "\n",
    "# Define optimizers, one per network\n",
    "optimizer_msd        = optim.Adam(msdnet_model.parameters(), lr=learning_rate)\n",
    "optimizer_tunet      = optim.Adam(tunet_model.parameters(), lr=learning_rate)\n",
    "optimizer_tunet3plus = optim.Adam(tunet3plus_model.parameters(), lr=learning_rate)\n",
    "optimizer_smsnet     = optim.Adam(smsnet_model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = \"cpu\" \n",
    "#device = helpers.get_device()  # Uncomment to get detected GPU\n",
    "\n",
    "print('Device we will compute on: ', device)   # cuda:0 for GPU. Else, CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6b171",
   "metadata": {},
   "source": [
    "### Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "worse-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 1.3394e-01 | Validation Loss: 1.3195e-01\n",
      "Training CC: 0.2318   Validation CC  : 0.2604 \n",
      "Epoch 20 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 1.2544e-01 | Validation Loss: 1.2512e-01\n",
      "Training CC: 0.3468   Validation CC  : 0.3533 \n",
      "Epoch 30 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 1.2006e-01 | Validation Loss: 1.1919e-01\n",
      "Training CC: 0.4306   Validation CC  : 0.4412 \n"
     ]
    }
   ],
   "source": [
    "msdnet_model.to(device)   \n",
    "msdnet_model, results = train_scripts.train_regression(msdnet_model,\n",
    "                                                       train_loader,\n",
    "                                                       test_loader,\n",
    "                                                       epochs,\n",
    "                                                       criterion,\n",
    "                                                       optimizer_msd,\n",
    "                                                       device,\n",
    "                                                       show=10)\n",
    "msdnet_model = msdnet_model.cpu()\n",
    "\n",
    "# clear out unnecessary variables from device (GPU) memory\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "documented-tribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 1.0465e-01 | Validation Loss: 1.0222e-01\n",
      "Training CC: 0.6277   Validation CC  : 0.6486 \n",
      "Epoch 20 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 9.0910e-02 | Validation Loss: 9.0148e-02\n",
      "Training CC: 0.7315   Validation CC  : 0.7369 \n",
      "Epoch 30 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 8.4621e-02 | Validation Loss: 8.4023e-02\n",
      "Training CC: 0.7680   Validation CC  : 0.7710 \n"
     ]
    }
   ],
   "source": [
    "tunet_model.to(device)   \n",
    "tunet_model, results = train_scripts.train_regression(tunet_model,\n",
    "                                                      train_loader,\n",
    "                                                      test_loader,\n",
    "                                                      epochs,\n",
    "                                                      criterion,\n",
    "                                                      optimizer_tunet,\n",
    "                                                      device,\n",
    "                                                      show=10)\n",
    "tunet_model = tunet_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baking-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 1.1597e-01 | Validation Loss: 1.0999e-01\n",
      "Training CC: 0.6223   Validation CC  : 0.6243 \n",
      "Epoch 20 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 9.3929e-02 | Validation Loss: 9.2382e-02\n",
      "Training CC: 0.7193   Validation CC  : 0.7255 \n",
      "Epoch 30 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 8.6973e-02 | Validation Loss: 8.6491e-02\n",
      "Training CC: 0.7595   Validation CC  : 0.7624 \n"
     ]
    }
   ],
   "source": [
    "tunet3plus_model.to(device)   \n",
    "tunet3plus_model, results = train_scripts.train_regression(tunet3plus_model,\n",
    "                                                           train_loader,\n",
    "                                                           test_loader,\n",
    "                                                           epochs,\n",
    "                                                           criterion,\n",
    "                                                           optimizer_tunet3plus,\n",
    "                                                           device,\n",
    "                                                           show=10)\n",
    "tunet3plus_model = tunet3plus_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "encouraging-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 1.3093e-01 | Validation Loss: 1.2912e-01\n",
      "Training CC: 0.5322   Validation CC  : 0.5617 \n",
      "Epoch 20 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 9.6700e-02 | Validation Loss: 9.6951e-02\n",
      "Training CC: 0.7224   Validation CC  : 0.7297 \n",
      "Epoch 30 of 30 | Learning rate 1.000e-02\n",
      "Training Loss: 9.0295e-02 | Validation Loss: 9.0044e-02\n",
      "Training CC: 0.7518   Validation CC  : 0.7524 \n"
     ]
    }
   ],
   "source": [
    "smsnet_model.to(device)   \n",
    "smsnet_model, results = train_scripts.train_regression(smsnet_model,\n",
    "                                                       train_loader,\n",
    "                                                       test_loader,\n",
    "                                                       epochs,\n",
    "                                                       criterion,\n",
    "                                                       optimizer_smsnet,\n",
    "                                                       device,\n",
    "                                                       show=10)\n",
    "smsnet_model = smsnet_model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc743f",
   "metadata": {},
   "source": [
    "## Save Networks\n",
    "\n",
    "Each network library contains submodule for saving the trained networks. Each instance saves in a .pt file the following:\n",
    "\n",
    "- model's state_dict: the network parameters learned through optimization/minimization during training,\n",
    "- model's topo_dict: the list of network hyperparameters needed to initialize the same architecture.\n",
    "\n",
    "This follows standard PyTorch practice; instead of saving massive trained networks, the pickled weights may simply be loaded into a freshly created network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "young-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "msdnet_model.save_network_parameters(\"this_msdnet.pt\")\n",
    "smsnet_model.save_network_parameters(\"this_smsnet.pt\")\n",
    "tunet_model.save_network_parameters(\"this_tunet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ced18",
   "metadata": {},
   "source": [
    "## Load networks from file\n",
    "\n",
    "Each network library loads in the .pt file containing architecture-governing hyperparameters and learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "separate-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_msdnet = msdnet.MSDNetwork_from_file(\"this_msdnet.pt\")\n",
    "copy_smsnet = smsnet.SMSNetwork_from_file(\"this_smsnet.pt\")\n",
    "copy_tunet = tunet.TUNetwork_from_file(\"this_tunet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd482ffe",
   "metadata": {},
   "source": [
    "### Verify loaded networks\n",
    "\n",
    "Network copies are loaded from file and checked against the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessory-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    r1 = msdnet_model(test_x)\n",
    "    r2 = copy_msdnet(test_x)\n",
    "delta = r1-r2\n",
    "assert torch.max(torch.abs(delta)) < 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "integral-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    r1 = smsnet_model(test_x)\n",
    "    r2 = copy_smsnet(test_x)\n",
    "delta = r1-r2\n",
    "assert torch.max(torch.abs(delta)) < 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hindu-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    r1 = tunet_model(test_x)\n",
    "    r2 = copy_tunet(test_x)\n",
    "delta = r1-r2\n",
    "assert torch.max(torch.abs(delta)) < 1e-8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
